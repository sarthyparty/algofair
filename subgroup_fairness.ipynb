{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from functions import metrics\n",
    "import csv\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from functions.formatting import get_subgroup_str\n",
    "from itertools import product, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_demographics = True \n",
    "use_gerryfair = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/preprocessed.csv')\n",
    "df.drop(['umich_user_id', 'Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('completed', axis=1)\n",
    "y = df['completed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate false positive rates for the given subgroup\n",
    "\n",
    "This function takes in the subgroup to test for as a list of tuples. We use logistic regression and 10-fold cross validation to calculate the average FPR and AUC for the given subgroup. \n",
    "\n",
    "Returns a tuple containing FPR average, FPR standard deviation, AUC average, AUC standard deviation, and number of students in a given subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute all subgroups\n",
    "\n",
    "This function generates all possible subgroups given the list of protected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_groups = [['US', 'intl'], ['bachelor_obtained', 'no_bachelor_obtained', 'education_na'], ['white', 'black', 'asian', 'latinx', 'race_others', 'race_na'], ['male', 'female', 'gender_na', 'gender_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combos():\n",
    "    ret = []\n",
    "    for i in range(1,len(demo_groups)+1):\n",
    "        g = list(combinations(demo_groups, i))\n",
    "        for demos in g:\n",
    "            ret += list(product(*demos))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = compute_combos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos.sort(key=len)\n",
    "# combos\n",
    "combos.insert(0, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = ['US', 'intl', 'bachelor_obtained', 'no_bachelor_obtained', 'education_na', 'white', 'black', 'asian', 'latinx', 'race_others', 'race_na', 'male', 'female', 'gender_na', 'gender_other']\n",
    "protected=['US', 'intl', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metrics.calc_metrics(X, y, combos, omit_demographics=True, demographics=demographics, protected=protected, is_gerryfair=False, iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of all subgroup data and write it to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"./data/MTC508_subgroup_data_without_demographics.csv\"\n",
    "# csv_file = \"test.csv\"\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = [\n",
    "        'subgroup', 'n', 'auc_avg', 'auc_std', 'fpr_avg', 'fpr_std', 'rmse_avg', 'rmse_std']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # Write the header row\n",
    "    for row in res:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "\n",
    "# data['overall'] = len(X)\n",
    "\n",
    "# for c in combos[1:]:\n",
    "#     masks = [X[name] == value for name, value in c]\n",
    "#     final_mask = pd.concat(masks, axis=1).all(axis=1)\n",
    "#     filter_X = X[final_mask]\n",
    "#     data[get_subgroup_str(c)] = len(filter_X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(list(data.items()), columns=['Key', 'Count'])\n",
    "\n",
    "# # Specify the CSV file path\n",
    "# csv_file_path = 'data/MTC508_data_counts.csv'\n",
    "\n",
    "# # Write the DataFrame to a CSV file\n",
    "# df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup_data = pd.read_csv('./data/MTC508_subgroup_data_without_demographics.csv')\n",
    "fpr_data = {}\n",
    "# loop through each subgroup\n",
    "# for each subgroup, get the corresponding data\n",
    "for index, row in subgroup_data.iterrows():\n",
    "    # print(f\"Index: {index}, fpr: {row['fpr_avg']}\")\n",
    "    fpr_data[row['subgroup']] = row['fpr_avg']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup_data = pd.read_csv('./data/MTC508_subgroup_data_without_demographics.csv')\n",
    "auc_data = {}\n",
    "# loop through each subgroup\n",
    "# for each subgroup, get the corresponding data\n",
    "for index, row in subgroup_data.iterrows():\n",
    "    # print(f\"Index: {index}, fpr: {row['fpr_avg']}\")\n",
    "    auc_data[row['subgroup']] = row['auc_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_iters(start, stop, step, attrs, protected):\n",
    "    ret_val_auc = []\n",
    "    ret_val_fpr = []\n",
    "    data = []\n",
    "    for i in range(start+1,stop+1,step):\n",
    "        data.append(metrics.calc_metrics(X, y, combos, omit_demographics=True, demographics=demographics, protected=protected, is_gerryfair=True, iters=i))\n",
    "    \n",
    "    for a in attrs:\n",
    "        aucs = []\n",
    "        fprs = []\n",
    "        for res in data:\n",
    "            for subgroup in res:\n",
    "                if subgroup['subgroup'] == a:\n",
    "                    aucs.append(float(subgroup['auc_avg']))\n",
    "                    fprs.append(float(subgroup['fpr_avg']))\n",
    "                    break\n",
    "\n",
    "        iterations = np.array(list(range(start, stop, step)))\n",
    "\n",
    "        other_algorithm_auc = np.linspace(auc_data[a], auc_data[a], iterations.size)\n",
    "        other_algorithm_fpr = np.linspace(fpr_data[a], fpr_data[a], iterations.size)\n",
    "\n",
    "        ret_val_auc.append((iterations, aucs, other_algorithm_auc))\n",
    "        ret_val_fpr.append((iterations, fprs, other_algorithm_fpr))\n",
    "    \n",
    "    return ret_val_auc, ret_val_fpr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['Overall', 'white', 'black', 'female', 'black, female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_auc, val_fpr = get_data_iters(0, 301, 20, attrs, ['white', 'black', 'asian', 'latinx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate(attrs):\n",
    "    iterations, fprs, other_algorithm_fpr = val[i]\n",
    "\n",
    "    df = pd.DataFrame({'x_axis': iterations, 'y_axis': fprs, 'other': other_algorithm_fpr})\n",
    "    df.to_csv('./data/graph_iters_auc_0_301_20_' + g + '.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for i, g in enumerate(attrs):\n",
    "    data = pd.read_csv('./data/graph_iters_fpr_0_1001_20' + g + '.csv')\n",
    "    line = [list(data['x_axis']), list(data['y_axis']), list(data['other'])]\n",
    "\n",
    "    val.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(x_axis, y_axis, other_algorithm_fpr, x_axis_label, y_axis_label, a):\n",
    "        plt.plot(x_axis, y_axis, linestyle='-', label='GerryFair')\n",
    "\n",
    "        plt.plot(x_axis, other_algorithm_fpr, linestyle='-', label='LR Without Gerryfair')\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        plt.xlabel(x_axis_label)\n",
    "        plt.ylabel(y_axis_label)\n",
    "        plt.title(f'Comparison of Algorithms - {y_axis_label} vs {x_axis_label} For ' + a.capitalize())\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"Overall\", \"White\", \"Black\", \"Female\", \"Black + Female\"]\n",
    "\n",
    "for i, attr in enumerate(attributes):\n",
    "    build_graph(val[i][0], val[i][1], val[i][2], 'Iterations', 'FPR', attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_combined_graph(val, attributes):\n",
    "    # Set distinct colors for each attribute\n",
    "    colors = ['b', 'g', 'r', 'c', 'm']  # You can add more colors if needed\n",
    "\n",
    "    # Create a single plot\n",
    "    plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "\n",
    "    for i, attr in enumerate(attributes):\n",
    "        x_axis, y_axis, other_algorithm_fpr = val[i]\n",
    "        plt.plot(x_axis, y_axis, linestyle='-', label=f'GerryFair - {attr.capitalize()}', color=colors[i])\n",
    "        plt.plot(x_axis, other_algorithm_fpr, linestyle='-', label=f'LR Without Gerryfair - {attr.capitalize()}', color=colors[i], alpha=0.5)\n",
    "\n",
    "    # Set the y-axis range to 0 to 1\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('FPR')\n",
    "    plt.title('Comparison of Algorithms - AUC vs Iterations (All Protected)')\n",
    "\n",
    "    # Move the legend outside the axes\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Automatically adjust subplot parameters to give specified padding\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "attributes = [\"Overall\", \"White\", \"Black\", \"Female\", \"Black + Female\"]\n",
    "\n",
    "build_combined_graph(val, attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_gamma(iters, gammas, attrs):\n",
    "    results = []\n",
    "    for g in gammas:\n",
    "        results.append(metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=['country_cd_US', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female'], is_gerryfair=True, iters=iters+1, gamma=g))\n",
    "    \n",
    "    data = results\n",
    "    for a in attrs:\n",
    "        fprs = []\n",
    "        for res in results:\n",
    "            for subgroup in res:\n",
    "                if subgroup['subgroup'] == a:\n",
    "                    fprs.append(float(subgroup['fpr_avg']))\n",
    "                    break\n",
    "        \n",
    "        fprs = np.array(fprs)\n",
    "        gammas = np.array(gammas)\n",
    "\n",
    "        other_algorithm_fpr = np.linspace(default_fprs[a], default_fprs[a], gammas.size) \n",
    "\n",
    "        plt.plot(gammas, fprs, marker='o', linestyle='-', label='GerryFair')\n",
    "\n",
    "        plt.plot(gammas, other_algorithm_fpr, marker='s', linestyle='-', label='Other Algorithm')\n",
    "\n",
    "        plt.xlabel('Gamma')\n",
    "        plt.ylabel('False Positive Rate (FPR)')\n",
    "        plt.title('Comparison of Algorithms - FPR vs Gamma For ' + a.capitalize())\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graph_gamma(5, [.002, .005, .01, .02, .05, .1], ['Overall', 'black', 'female', 'black, female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_attrs(iters, attrs, sets):\n",
    "    results = []\n",
    "    for i in range(len(sets)):\n",
    "        results.append(metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=demographics[:i+1], is_gerryfair=True, iters=iters+1, gamma=g))\n",
    "    \n",
    "    for a in attrs:\n",
    "        fprs = []\n",
    "        for res in results:\n",
    "            for subgroup in res:\n",
    "                if subgroup['subgroup'] == a:\n",
    "                    fprs.append(float(subgroup['fpr_avg']))\n",
    "                    break\n",
    "        \n",
    "        fprs = np.array(fprs)\n",
    "        num_attrs = np.array(list(range(1,len(demographics) + 1)))\n",
    "\n",
    "        other_algorithm_fpr = np.linspace(default_fprs[a], default_fprs[a], len(demographics)) \n",
    "\n",
    "        plt.plot(num_attrs, fprs, marker='o', linestyle='-', label='GerryFair')\n",
    "\n",
    "        plt.plot(num_attrs, other_algorithm_fpr, marker='s', linestyle='-', label='Other Algorithm')\n",
    "\n",
    "        plt.xlabel('Number of Attributes')\n",
    "        plt.ylabel('False Positive Rate (FPR)')\n",
    "        plt.title('Comparison of Algorithms - FPR vs Number of Attributes For ' + a.capitalize())\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerryfair_groups = {\n",
    "    'all': protected,\n",
    "    'location': demo_groups[0], \n",
    "    'education': demo_groups[1][:-1], \n",
    "    'race': demo_groups[2][:-2], \n",
    "    'gender': demo_groups[3][:-2],\n",
    "    'race+gender': demo_groups[2][:-2] + demo_groups[3][:-2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_categories(iters, attrs):\n",
    "    for g in attrs:\n",
    "        res = metrics.calc_metrics(X, y, combos, omit_demographics=False, demographics=demographics, protected=attrs[g], is_gerryfair=True, iters=iters)\n",
    "        csv_file = f\"./data/graph_attrs_{str(iters)}_{g}.csv\"\n",
    "\n",
    "        # Write the data to a CSV file\n",
    "        with open(csv_file, 'w', newline='') as csvfile:\n",
    "            fieldnames = [\n",
    "                'subgroup', 'n', 'auc_avg', 'auc_std', 'fpr_avg', 'fpr_std', 'rmse_avg', 'rmse_std']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()  # Write the header row\n",
    "            for row in res:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_categories(200, gerryfair_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_groups[2][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
