{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from functions import metrics\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functions.formatting import get_indices, get_subgroup_str\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_demographics = False \n",
    "use_gerryfair = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/preprocessed.csv')\n",
    "df.drop(['umich_user_id', 'Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('completed', axis=1)\n",
    "y = df['completed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate false positive rates for the given subgroup\n",
    "\n",
    "This function takes in the subgroup to test for as a list of tuples. We use logistic regression and 10-fold cross validation to calculate the average FPR and AUC for the given subgroup. \n",
    "\n",
    "Returns a tuple containing FPR average, FPR standard deviation, AUC average, AUC standard deviation, and number of students in a given subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute all subgroups\n",
    "\n",
    "This function generates all possible subgroups given the list of protected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combo(cols, races, genders):\n",
    "    retval = [[]]\n",
    "    def recurse(i, curr):\n",
    "        for r in races:\n",
    "            opt3 = curr.copy()\n",
    "            opt3.append((r, 1))\n",
    "            if opt3 not in retval:\n",
    "                retval.append(opt3)\n",
    "        for g in genders:\n",
    "            opt4 = curr.copy()\n",
    "            opt4.append((g, 1))\n",
    "            if opt4 not in retval:\n",
    "                retval.append(opt4)\n",
    "        for r in races:\n",
    "            for g in genders:\n",
    "                opt5 = curr.copy()\n",
    "                opt5.append((r, 1))\n",
    "                opt5.append((g, 1))\n",
    "                if opt5 not in retval:\n",
    "                    retval.append(opt5)\n",
    "        for j in range(i, len(cols)):\n",
    "            opt1 = curr.copy()\n",
    "            opt1.append((cols[j], 0))\n",
    "\n",
    "            opt2 = curr.copy()\n",
    "            opt2.append((cols[j], 1))\n",
    "            \n",
    "            retval.append(opt1)\n",
    "            retval.append(opt2)\n",
    "            \n",
    "            if j < len(cols):\n",
    "                recurse(j+1, opt1.copy())\n",
    "            if j < len(cols):\n",
    "                recurse(j+1, opt2.copy())\n",
    "        \n",
    "    recurse(0, [])\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = compute_combo(['country_cd_US', 'bachelor_obtained'], ['white', 'black', 'asian', 'latinx', 'race_others', 'race_na'], ['male', 'female', 'gender_na', 'gender_other']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos.sort(key=len)\n",
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {}\n",
    "for combo in combos:\n",
    "    group_key = []\n",
    "    for c in combo:\n",
    "        group_key.append(c[0])\n",
    "    if tuple(group_key) not in groups:\n",
    "        groups[tuple(group_key)] = []\n",
    "    groups[tuple(group_key)].append(combo)\n",
    "\n",
    "# sort dict by length of key\n",
    "groups = dict(sorted(groups.items(), key=lambda item: len(item[0])))\n",
    "\n",
    "print(groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=['country_cd_US', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female'], is_gerryfair=True, iters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of all subgroup data and write it to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"./data/MTC508_subgroup_data_gerryfair_with_all.csv\"\n",
    "# csv_file = \"test.csv\"\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = [\n",
    "        'subgroup', 'n', 'auc_avg', 'auc_std', 'fpr_avg', 'fpr_std', 'rmse_avg', 'rmse_std']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # Write the header row\n",
    "    for row in res:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_groups = [['country_cd_US'], ['bachelor_obtained'], ['white', 'black', 'asian', 'latinx', 'race_others', 'race_na'], ['male', 'female', 'gender_other', 'gender_na']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['overall'] = len(X)\n",
    "\n",
    "for c in combos[1:]:\n",
    "    masks = [X[name] == value for name, value in c]\n",
    "    final_mask = pd.concat(masks, axis=1).all(axis=1)\n",
    "    filter_X = X[final_mask]\n",
    "    data[get_subgroup_str(c)] = len(filter_X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(data.items()), columns=['Key', 'Count'])\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'data/MTC508_data_counts.csv'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(2,11):\n",
    "    data.append(metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=['country_cd_US', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female'], is_gerryfair=True, iters=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs = []\n",
    "for res in data:\n",
    "    for subgroup in res:\n",
    "        if subgroup['subgroup'] == 'Overall':\n",
    "            fprs.append(float(subgroup['fpr_avg']))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs = np.array(fprs)\n",
    "fprs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "iterations = np.arange(1, 10)\n",
    "\n",
    "other_algorithm_fpr = np.linspace(0.5, 0.5, 9) \n",
    "\n",
    "plt.plot(iterations, fprs, marker='o', linestyle='-', label='GerryFair')\n",
    "\n",
    "plt.plot(iterations, other_algorithm_fpr, marker='s', linestyle='-', label='Other Algorithm')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('False Positive Rate (FPR)')\n",
    "plt.title('Comparison of Algorithms - FPR vs Iterations')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = ['country_cd_US', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fprs = {\"Overall\": 0.157, \"black\": 0.360, \"female\": 0.177, \"black, female\": 0.537}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_iters(start, stop, step, attrs):\n",
    "    data = []\n",
    "    for i in range(start+1,stop+1,step):\n",
    "        data.append(metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=['country_cd_US', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female'], is_gerryfair=True, iters=i))\n",
    "    \n",
    "\n",
    "    for a in attrs:\n",
    "        fprs = []\n",
    "        for res in data:\n",
    "            \n",
    "            for subgroup in res:\n",
    "                if subgroup['subgroup'] == a:\n",
    "                    fprs.append(float(subgroup['fpr_avg']))\n",
    "                    break\n",
    "\n",
    "        iterations = np.array(list(range(start, stop, step)))\n",
    "\n",
    "        other_algorithm_fpr = np.linspace(default_fprs[a], default_fprs[a], iterations.size) \n",
    "\n",
    "        plt.plot(iterations, fprs, marker='o', linestyle='-', label='GerryFair')\n",
    "\n",
    "        plt.plot(iterations, other_algorithm_fpr, marker='s', linestyle='-', label='Other Algorithm')\n",
    "\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('False Positive Rate (FPR)')\n",
    "        plt.title('Comparison of Algorithms - FPR vs Iterations For ' + a.capitalize())\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graph_iters(1,10,1,['Overall', 'black', 'female', 'black, female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_gamma(iters, gammas, attrs):\n",
    "    results = []\n",
    "    for g in gammas:\n",
    "        results.append(metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=['country_cd_US', 'bachelor_obtained', 'white', 'black', 'asian', 'latinx', 'male', 'female'], is_gerryfair=True, iters=iters+1, gamma=g))\n",
    "    \n",
    "    data = results\n",
    "    for a in attrs:\n",
    "        fprs = []\n",
    "        for res in results:\n",
    "            for subgroup in res:\n",
    "                if subgroup['subgroup'] == a:\n",
    "                    fprs.append(float(subgroup['fpr_avg']))\n",
    "                    break\n",
    "        \n",
    "        fprs = np.array(fprs)\n",
    "        gammas = np.array(gammas)\n",
    "\n",
    "        other_algorithm_fpr = np.linspace(default_fprs[a], default_fprs[a], gammas.size) \n",
    "\n",
    "        plt.plot(gammas, fprs, marker='o', linestyle='-', label='GerryFair')\n",
    "\n",
    "        plt.plot(gammas, other_algorithm_fpr, marker='s', linestyle='-', label='Other Algorithm')\n",
    "\n",
    "        plt.xlabel('Gamma')\n",
    "        plt.ylabel('False Positive Rate (FPR)')\n",
    "        plt.title('Comparison of Algorithms - FPR vs Gamma For ' + a.capitalize())\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graph_gamma(5, [.002, .005, .01, .02, .05, .1], ['Overall', 'black', 'female', 'black, female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_attrs(iters, attrs):\n",
    "    results = []\n",
    "    for i in range(len(demographics)):\n",
    "        results.append(metrics.calc_metrics(X, y, groups, omit_demographics=not include_demographics, demographics=demographics[:i+1], is_gerryfair=True, iters=iters+1, gamma=g))\n",
    "    \n",
    "    for a in attrs:\n",
    "        fprs = []\n",
    "        for res in results:\n",
    "            for subgroup in res:\n",
    "                if subgroup['subgroup'] == a:\n",
    "                    fprs.append(float(subgroup['fpr_avg']))\n",
    "                    break\n",
    "        \n",
    "        fprs = np.array(fprs)\n",
    "        num_attrs = np.array(list(range(1,len(demographics) + 1)))\n",
    "\n",
    "        other_algorithm_fpr = np.linspace(default_fprs[a], default_fprs[a], len(demographics)) \n",
    "\n",
    "        plt.plot(num_attrs, fprs, marker='o', linestyle='-', label='GerryFair')\n",
    "\n",
    "        plt.plot(num_attrs, other_algorithm_fpr, marker='s', linestyle='-', label='Other Algorithm')\n",
    "\n",
    "        plt.xlabel('Number of Attributes')\n",
    "        plt.ylabel('False Positive Rate (FPR)')\n",
    "        plt.title('Comparison of Algorithms - FPR vs Number of Attributes For ' + a.capitalize())\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_graph_attrs(5, ['Overall', 'black', 'female', 'black, female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
